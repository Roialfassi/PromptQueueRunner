Dynamic Programming (DP) is an efficient method for solving complex optimization problems. The core idea behind DP is to break down the original problem into smaller overlapping sub-problems.

The principle of optimality states that the optimal solution to a given problem can be constructed from optimal solutions to its sub-problems. This principle leads us to formulate and solve the sub-problems iteratively, storing solutions for these problems in a table (usually two-dimensional). 

Solving problems with overlapping subproblems using DP typically involves the following steps:
1. Identify the problem as a function of one or more variables. 
2. Formulate the problem in terms of solving a series of smaller problems that overlap each other.
3. Define an optimal solution for the original problem based on the optimal solutions to its sub-problems. This definition is known as the principle of optimality.
4. Use a table (usually two-dimensional) to store and organize the solutions to the sub-problems. The row(s) in this table represent the different values that the variables can take, while the column(s) represent the optimal solution for each possible combination of variable values.
5. Iterate over the rows in the table (excluding the first row), and for each row, calculate or retrieve the optimal solution to the original problem based on the solutions to its sub-problems stored in the previous rows of the table.
6. Once all the rows have been processed, the final column of the table will contain the optimal solution to the original problem.

By applying dynamic programming techniques and using appropriate data structures (usually two-dimensional tables), we can efficiently solve complex optimization problems with overlapping subproblems in polynomial time.